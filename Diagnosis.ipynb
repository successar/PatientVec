{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-12 11:26:51,141 - Reading Structured data ...\n",
      "INFO - 2019-02-12 11:26:51,238 - Reading Notes ...\n",
      "INFO - 2019-02-12 11:27:01,141 - Stratifying ...\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(name='Diagnosis', dirname='preprocess/Diagnosis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labellist = [x for x in data.dataframe.columns if x.startswith('y_')]\n",
    "data.generate_labels(labellist, len(labellist), 'multilabel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.generate_encoded_field('gender_y', 'onehot')\n",
    "data.generate_encoded_field('age_y', 'onehot')\n",
    "data.generate_encoded_field('ethnicity_y', 'onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in data.dataframe.columns if x.startswith('feature')]\n",
    "for f in features :\n",
    "    data.generate_encoded_field(f, 'trivial')\n",
    "    \n",
    "data.set_structured_params(regexs=[r'^feature', 'gender_y', 'age_y', 'ethnicity_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Vanilla import ClassificationTrainer as BasicCT\n",
    "from models.Hierarchical import ClassificationTrainer as HierCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Experiments.experiments import experiments, hierarchical_experiments, structured_experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Experiments\n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Percentage [0.21358209 0.07716941 0.10244004 0.31971179 0.13028647 0.13014724\n",
      " 0.20870897 0.07160013 0.26850917 0.31939852 0.09485189 0.19033033\n",
      " 0.28253681 0.41581677 0.26697762 0.07180897 0.13039089 0.0897003\n",
      " 0.04953183 0.04076021 0.08917818 0.14152947 0.18249852 0.14615893\n",
      " 0.07797   ]\n",
      "Pos Percentage [0.20548768 0.06969758 0.10194272 0.31744442 0.12237132 0.13458842\n",
      " 0.2032846  0.06649309 0.25776087 0.31484078 0.0929301  0.19587422\n",
      " 0.29541358 0.42339275 0.25475666 0.06789505 0.12096936 0.08531945\n",
      " 0.0530743  0.03745243 0.0817144  0.1327859  0.17684759 0.13198478\n",
      " 0.07790907]\n",
      "Pos Percentage [0.20977494 0.06768559 0.10732281 0.32129661 0.12512597 0.12395029\n",
      " 0.21229426 0.06902922 0.26603964 0.32935841 0.09103124 0.19146792\n",
      " 0.28081962 0.42122943 0.26184078 0.07910648 0.12428619 0.08834397\n",
      " 0.05424924 0.04165267 0.09271078 0.13671481 0.17954316 0.14124958\n",
      " 0.08095398]\n"
     ]
    }
   ],
   "source": [
    "train_data = data.get_data('train', structured=True)\n",
    "dev_data = data.get_data('dev', structured=True)\n",
    "test_data = data.get_data('test', structured=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-12 11:27:18,567 - Maximum Sentence Length 721825.000000 , 90 percentile length 16714.400000 ... \n",
      "INFO - 2019-02-12 11:27:18,573 - Pos Percentage of remaining data ... \n",
      "INFO - 2019-02-12 11:27:18,594 - [0.19322401 0.07650062 0.10272277 0.3112237  0.12059097 0.12650835\n",
      " 0.20064975 0.07023515 0.25978496 0.32545637 0.09316986 0.18722927\n",
      " 0.28480817 0.42090811 0.24957457 0.06973236 0.1237237  0.08249536\n",
      " 0.04641089 0.03774752 0.08048422 0.12349165 0.15741027 0.12925433\n",
      " 0.06845606]\n",
      "INFO - 2019-02-12 11:27:19,378 - Maximum Sentence Length 407062.000000 , 90 percentile length 16420.400000 ... \n",
      "INFO - 2019-02-12 11:27:19,380 - Pos Percentage of remaining data ... \n",
      "INFO - 2019-02-12 11:27:19,383 - [0.18517694 0.06877365 0.10549744 0.30847986 0.11395504 0.12819942\n",
      " 0.19719564 0.06543512 0.24905408 0.32383708 0.09014022 0.19519252\n",
      " 0.30202537 0.42777654 0.23213888 0.06209659 0.1135099  0.07834409\n",
      " 0.04941019 0.03360783 0.07589584 0.11551302 0.1502337  0.11662586\n",
      " 0.06855108]\n"
     ]
    }
   ],
   "source": [
    "train_data = data.filter_data_length(train_data, truncate=90)\n",
    "dev_data = data.filter_data_length(dev_data, truncate=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in experiments :\n",
    "    config = e(data, structured=True)\n",
    "    print(config)\n",
    "    trainer = Trainer(BasicCT, config, _type='multilabel')\n",
    "    trainer.train(train_data, dev_data, save_on_metric='macro_roc_auc')\n",
    "\n",
    "    evaluator = Evaluator(BasicCT, trainer.model.dirname, _type='multilabel')\n",
    "    _ = evaluator.evaluate(dev_data, save_results=True)\n",
    "    print('='*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in hierarchical_experiments :\n",
    "    config = e(data, structured=False)\n",
    "    print(config)\n",
    "    trainer = Trainer(HierCT, config)\n",
    "    trainer.train(train_data, dev_data)\n",
    "\n",
    "    evaluator = Evaluator(HierCT, trainer.model.dirname)\n",
    "    _ = evaluator.evaluate(dev_data, save_results=True)\n",
    "    print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.get_data('train', structured=True, encodings=data.structured_columns)\n",
    "dev_data = data.get_data('dev', structured=True, encodings=data.structured_columns)\n",
    "train_data = data.filter_data_length(train_data, truncate=90)\n",
    "dev_data = data.filter_data_length(dev_data, truncate=90)\n",
    "\n",
    "for e in structured_experiments :\n",
    "    config = e(data, structured=True, encodings=data.structured_columns)\n",
    "    print(config)\n",
    "    \n",
    "    trainer = Trainer(BasicCT, config)\n",
    "    trainer.train(train_data, dev_data)\n",
    "\n",
    "    evaluator = Evaluator(BasicCT, trainer.model.dirname)\n",
    "    _ = evaluator.evaluate(dev_data, save_results=True)\n",
    "    print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatientVec.models.baselines.LR import LR, LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0c1dd0217e494487b3651ba81a6503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2de154e89c0402c882b3ecb0edc6aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33db329736304dacb1b607429af8db4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25856), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fit BOW Classifier ...\n",
      "Fit TFIDF Classifier ...\n"
     ]
    }
   ],
   "source": [
    "lr = LR({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name, 'type' : 'multilabel'})\n",
    "lr.train(train_data)\n",
    "lr.evaluate(dev_data, save_results=True)\n",
    "# lr.get_features(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name})\n",
    "lda.train(train_data)\n",
    "lda.evaluate(dev_data, save_results=True)\n",
    "print(lda.get_topics(n=10))\n",
    "topics = lda.get_topics(n=10)\n",
    "print([topics[i] for i in np.argsort(lda.lda_classifier.coef_[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[topics[i] for i in np.argsort(lda.lda_classifier.coef_[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = outputs['predictions'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import collapse_and_print_word_attn, print_sent_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "collapse_and_print_word_attn(data.vocab, dev_data.X[n], outputs['word_attentions'][n])\n",
    "print_sent_attn(data.vocab, dev_data.X[n], outputs['sentence_attentions'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['sentence_attentions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = [kendalltau(range(len(outputs['sentence_attentions'][i])), outputs['sentence_attentions'][i]) \n",
    "         for i in range(len(outputs['sentence_attentions']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, leng = zip(*[(x[0], y) for x, y in zip(corrs, [len(z) for z in outputs['sentence_attentions']]) if x[0] == x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rho, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval, leng1 = zip(*[(x[1], y) for x, y in zip(corrs, [len(z) for z in outputs['sentence_attentions']]) if x[1] == x[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Models\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for e in experiments :\n",
    "    config = e(data, structured=False)\n",
    "    filename = config['exp_config']['exp_name']\n",
    "    filename = os.path.join('outputs/classification/', filename)\n",
    "    push_latest_model(filename, config['exp_config']['exp_name'])\n",
    "    \n",
    "    config = e(data, structured=True)\n",
    "    filename = config['exp_config']['exp_name']\n",
    "    filename = os.path.join('outputs/classification/', filename)\n",
    "    push_latest_model(filename, config['exp_config']['exp_name'])\n",
    "    \n",
    "for e in hierarchical_experiments :\n",
    "    config = e(data, structured=False)\n",
    "    filename = config['exp_config']['exp_name']\n",
    "    filename = os.path.join('outputs/hierarchical_classification/', filename)\n",
    "    push_latest_model(filename, config['exp_config']['exp_name'])\n",
    "    \n",
    "    config = e(data, structured=True)\n",
    "    filename = config['exp_config']['exp_name']\n",
    "    filename = os.path.join('outputs/hierarchical_classification/', filename)\n",
    "    push_latest_model(filename, config['exp_config']['exp_name'])\n",
    "    \n",
    "for e in structured_experiments :\n",
    "    config = e(data, structured=True, encodings=['gender_y', 'ethnicity_y', 'age_y'])\n",
    "    filename = config['exp_config']['exp_name']\n",
    "    filename = os.path.join('outputs/classification/', filename)\n",
    "    push_latest_model(filename, config['exp_config']['exp_name'])\n",
    "    \n",
    "    config = e(data, structured=False, encodings=['gender_y', 'ethnicity_y', 'age_y'])\n",
    "    filename = config['exp_config']['exp_name']\n",
    "    filename = os.path.join('outputs/classification/', filename)\n",
    "    push_latest_model(filename, config['exp_config']['exp_name'])\n",
    "    \n",
    "    config = e(data, structured=True, encodings=data.structured_columns)\n",
    "    filename = config['exp_config']['exp_name']\n",
    "    filename = os.path.join('outputs/classification/', filename)\n",
    "    push_latest_model(filename, config['exp_config']['exp_name'])\n",
    "    \n",
    "    config = e(data, structured=False, encodings=data.structured_columns)\n",
    "    filename = config['exp_config']['exp_name']\n",
    "    filename = os.path.join('outputs/classification/', filename)\n",
    "    push_latest_model(filename, config['exp_config']['exp_name'])\n",
    "    \n",
    "    \n",
    "for e in os.listdir('outputs/baselines/Readmission_y/baselines/') :\n",
    "    filename = os.path.join('outputs/baselines/Readmission_y/baselines/', e)\n",
    "    push_latest_model(filename, os.path.join('Readmission_y/baselines/', e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Readmission_y'\n",
    "dataset_path = os.path.join('latex_evals', dataset)\n",
    "output_path = os.path.join('Text-encoding-EHR/results/', dataset)\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(dataset_path)\n",
    "keys_to_use = ['1/precision', '1/recall', '1/f1-score', 'accuracy', 'roc_auc', 'pr_auc']\n",
    "for d in dirs :\n",
    "    subpath = os.path.join(dataset_path, d)\n",
    "    output_file = os.path.join(output_path, d + '.csv')\n",
    "    dfs = []\n",
    "    for f in sorted(os.listdir(subpath)) :\n",
    "        if os.path.isfile(os.path.join(subpath, f)) :\n",
    "            d = json.load(open(os.path.join(subpath, f)))\n",
    "            results = {k:d['results'][k] for k in keys_to_use}\n",
    "            results['Method'] = f[:-14].replace('+', ' +').replace('_', ':')\n",
    "            dfs.append(pd.DataFrame([results]))\n",
    "        else :\n",
    "            logging.error(\"%s not a file\", f)\n",
    "    \n",
    "    dfs = pd.concat(dfs)\n",
    "    dfs.to_csv(output_file, columns=['Method'] + keys_to_use, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
