{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Run Diagnosis experiments')\n",
    "parser.add_argument(\"--data_dir\", type=str, required=True)\n",
    "parser.add_argument('--display', dest='display', action='store_true')\n",
    "parser.add_argument(\"--output_dir\", type=str)\n",
    "parser.add_argument(\"--mock\", dest='mock', action='store_true')\n",
    "\n",
    "args = parser.parse_args(['--data_dir=.', '--output_dir=outputs/', '--display'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import readmission_dataset\n",
    "data = readmission_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatientVec.models.baselines.LR import LR, LDA\n",
    "from PatientVec.Experiments.hyperparam_exps import get_basic_data\n",
    "\n",
    "train_data, dev_data = get_basic_data(data, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name, 'type' : 'classifier', 'norm' : 'l1', 'clip' : True})\n",
    "lr.train(train_data)\n",
    "lr.evaluate(dev_data, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name, 'type' : 'classifier', 'norm' : 'l1', 'clip' : False})\n",
    "lr.train(train_data)\n",
    "lr.evaluate(dev_data, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name, 'type' : 'classifier', 'norm' : None, 'clip' : True})\n",
    "lr.train(train_data)\n",
    "lr.evaluate(dev_data, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name, 'type' : 'classifier', 'norm' : 'max', 'clip' : False})\n",
    "lr.train(train_data)\n",
    "lr.evaluate(dev_data, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name, 'type' : 'classifier', 'norm' : 'l3', 'clip' : False})\n",
    "lr.train(train_data)\n",
    "lr.evaluate(dev_data, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.evaluate(dev_data, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.print_all_features(n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tf = lr.get_features(classifier=lr.tf_idf_classifier, estimator=0, n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Models\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import generate_latex_tables\n",
    "keys_to_use = ['roc_auc', 'pr_auc']\n",
    "generate_latex_tables(data, keys_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'outputs/Readmission/Basic/'\n",
    "exps = os.listdir(dirname)\n",
    "for e in sorted(exps) :\n",
    "    if 'Structured' in e :\n",
    "        print(e)\n",
    "        print_results_from_model(get_latest_model(os.path.join(dirname, e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'outputs/Diagnosis/Basic/'\n",
    "exps = os.listdir(dirname)\n",
    "for e in sorted(exps) :\n",
    "    if 'Structured' in e :\n",
    "        print(e)\n",
    "        print_results_from_model(get_latest_model(os.path.join(dirname, e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
