{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Run Diagnosis experiments')\n",
    "parser.add_argument(\"--data_dir\", type=str, required=True)\n",
    "parser.add_argument('--display', dest='display', action='store_true')\n",
    "parser.add_argument(\"--output_dir\", type=str)\n",
    "parser.add_argument(\"--mock\", dest='mock', action='store_true')\n",
    "\n",
    "args = parser.parse_args(['--data_dir=.', '--output_dir=outputs/', '--display'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-20 16:23:26,393 - Reading Structured data ...\n",
      "INFO - 2019-02-20 16:23:26,826 - Reading Notes ...\n",
      "INFO - 2019-02-20 16:23:48,958 - Stratifying ...\n"
     ]
    }
   ],
   "source": [
    "from dataloaders import readmission_dataset\n",
    "data = readmission_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatientVec.Experiments.training_exps import get_basic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data = get_basic_data(data, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.generate_bowder(train_data, stop_words=True, norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.X = data.get_vec_encoding(train_data, _type='tfidf')\n",
    "dev_data.X = data.get_vec_encoding(dev_data, _type='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.X = np.array(train_data.X.todense())\n",
    "dev_data.X = np.array(dev_data.X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatientVec.Experiments.configs import vector_experiment\n",
    "config = vector_experiment(data)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer, Evaluator\n",
    "from models.Baseline import ClassificationTrainer as BaseCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(BaseCT, config, _type=data.metrics_type, display_metrics=args.display)\n",
    "trainer.train(train_data, dev_data, save_on_metric=data.save_on_metric)\n",
    "\n",
    "evaluator = Evaluator(BaseCT, trainer.model.dirname, _type=data.metrics_type, display_metrics=args.display)\n",
    "_ = evaluator.evaluate(dev_data, save_results=True)\n",
    "print('='*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Percentage [0.19738451]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-20 16:33:21,730 - Maximum Sentence Length 721825.000000 , 100 percentile length 721825.000000 ... \n",
      "INFO - 2019-02-20 16:33:21,748 - Pos Percentage of remaining data ... \n",
      "INFO - 2019-02-20 16:33:21,771 - [0.19738451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Percentage [0.20937082]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-20 16:33:24,836 - Maximum Sentence Length 588265.000000 , 100 percentile length 588265.000000 ... \n",
      "INFO - 2019-02-20 16:33:24,840 - Pos Percentage of remaining data ... \n",
      "INFO - 2019-02-20 16:33:24,846 - [0.20937082]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6e8fedd86940cf8ed373d43e46c2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29440), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e94040538384923a6071814dab5f41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29440), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581feefbd0a144d3901ec6ee71fff5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29440), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fit BOW Classifier ...\n",
      "Fit TFIDF Classifier ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5c99f9832f48ef98322cbf8faf89d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7470), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e939063b1d4c98b71efb24fb928d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7470), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BOW\n",
      "{'accuracy': 0.6985274431057563, 'roc_auc': 0.7496373816388553, 'pr_auc': 0.47691187909315513}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>micro avg</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.715</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>5906.000</td>\n",
       "      <td>1564.000</td>\n",
       "      <td>7470.000</td>\n",
       "      <td>7470.000</td>\n",
       "      <td>7470.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1  micro avg  macro avg  weighted avg\n",
       "f1-score      0.789     0.470      0.699      0.630         0.722\n",
       "precision     0.882     0.372      0.699      0.627         0.775\n",
       "recall        0.715     0.637      0.699      0.676         0.699\n",
       "support    5906.000  1564.000   7470.000   7470.000      7470.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF\n",
      "{'accuracy': 0.7111111111111111, 'roc_auc': 0.7528239195824092, 'pr_auc': 0.4841267575799175}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>micro avg</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.732</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>5906.000</td>\n",
       "      <td>1564.000</td>\n",
       "      <td>7470.000</td>\n",
       "      <td>7470.000</td>\n",
       "      <td>7470.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1  micro avg  macro avg  weighted avg\n",
       "f1-score      0.800     0.478      0.711      0.639         0.733\n",
       "precision     0.882     0.384      0.711      0.633         0.778\n",
       "recall        0.732     0.632      0.711      0.682         0.711\n",
       "support    5906.000  1564.000   7470.000   7470.000      7470.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PatientVec.models.baselines.LR import LR, LDA\n",
    "from PatientVec.Experiments.hyperparam_exps import get_basic_data\n",
    "\n",
    "train_data, dev_data = get_basic_data(data, truncate=100)\n",
    "lr = LR({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name, 'type' : 'classifier', 'norm' : 'l2'})\n",
    "lr.train(train_data)\n",
    "lr.evaluate(dev_data, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tube narrowing brown requesting thrombocytopenia jaundice guided encephalopathy vre chronically anasarca j enteric picc coagulopathy cancer duoderm jaundiced metastatic tumor coccyx prednisone amiodarone monday meeting endovascular icteric iv_contrast dialysis thoracentesis ascites subdural admissions paracentesis transplant vd onc prognosis dnr cmo\n",
      "----------\n",
      "metastatic dialysis pea cancer brown tears times prednisone palliative coarse coccyx chronically tube picc duoderm tumor 7.31 transtentorial coagulopathy listerine iv_contrast paracentesis ankylosing transplant ascites subdural icteric monday amiodarone meeting jaundiced bmt thoracentesis onc admissions endovascular vd prognosis dnr cmo\n",
      "----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiOutputClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5bd47508b31d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/jainsarthak/data/projects/PatientVec/models/baselines/LR.py\u001b[0m in \u001b[0;36mprint_all_features\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_idf_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbow_with_structured_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_idf_with_structured_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/jainsarthak/data/projects/PatientVec/models/baselines/LR.py\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(self, classifier, estimator, n)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         return [self.bowder.vocab.idx2word[self.bowder.map_bow_to_vocab[x]] for x in \n\u001b[0;32m---> 85\u001b[0;31m                     np.argsort(classifier.estimators_[estimator].coef_[0][:len(self.bowder.words_to_keep)])[-n:]]\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiOutputClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "lr.print_all_features(n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tf = lr.get_features(classifier=lr.tf_idf_classifier, estimator=0, n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Comparison\n",
    "===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from PatientVec.models.Vanilla import ClassificationTrainer as BasicCT\n",
    "from PatientVec.models.Hierarchical import ClassificationTrainer as HierCT\n",
    "from PatientVec.trainer import Trainer, Evaluator\n",
    "from PatientVec.Experiments.modifiable_config_exp import vanilla_configs, attention_configs, hierarchical_configs, structured_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-20 16:48:08,905 - instantiating class <class 'PatientVec.models.Model.Model'> from params {'type': 'seq_classifier_with_attention', 'embedder': {'type': 'token_embedder', 'vocab_size': 32246, 'embed_size': 200, 'embedding_file': 'preprocess/Readmission//embedding_matrix.npy'}, 'decoder': {'num_layers': 2, 'hidden_dims': [128, 1], 'activations': ['tanh', 'linear']}, 'predictor': {'type': 'binary'}, 'structured': {'use_structured': True, 'structured_dim': 142}, 'encoder': {'type': 'cnn', 'hidden_size': 64, 'kernel_sizes': [3, 5, 7, 9], 'activation': 'relu'}, 'attention': {'similarity': {'type': 'additive', 'hidden_size': 128}}} and extras {}\n",
      "INFO - 2019-02-20 16:48:08,907 - type = seq_classifier_with_attention\n",
      "INFO - 2019-02-20 16:48:08,908 - instantiating class <class 'PatientVec.models.modules.Embedder.Embedder'> from params {'type': 'token_embedder', 'vocab_size': 32246, 'embed_size': 200, 'embedding_file': 'preprocess/Readmission//embedding_matrix.npy'} and extras {}\n",
      "INFO - 2019-02-20 16:48:08,909 - embedder.type = token_embedder\n",
      "INFO - 2019-02-20 16:48:08,910 - instantiating class <class 'PatientVec.models.modules.Embedder.TokenEmbedder'> from params {'vocab_size': 32246, 'embed_size': 200, 'embedding_file': 'preprocess/Readmission//embedding_matrix.npy'} and extras {}\n",
      "INFO - 2019-02-20 16:48:08,913 - embedder.vocab_size = 32246\n",
      "INFO - 2019-02-20 16:48:08,913 - embedder.embed_size = 200\n",
      "INFO - 2019-02-20 16:48:08,914 - embedder.embedding_file = preprocess/Readmission//embedding_matrix.npy\n",
      "INFO - 2019-02-20 16:48:08,962 - instantiating class <class 'PatientVec.models.modules.Encoder.Encoder'> from params {'type': 'cnn', 'hidden_size': 64, 'kernel_sizes': [3, 5, 7, 9], 'activation': 'relu'} and extras {'input_size': 200}\n",
      "INFO - 2019-02-20 16:48:08,962 - encoder.type = cnn\n",
      "INFO - 2019-02-20 16:48:08,964 - instantiating class <class 'PatientVec.models.modules.Encoder.CNNEncoder'> from params {'hidden_size': 64, 'kernel_sizes': [3, 5, 7, 9], 'activation': 'relu'} and extras {'input_size': 200}\n",
      "INFO - 2019-02-20 16:48:08,965 - encoder.hidden_size = 64\n",
      "INFO - 2019-02-20 16:48:08,966 - encoder.kernel_sizes = [3, 5, 7, 9]\n",
      "INFO - 2019-02-20 16:48:08,966 - encoder.activation = relu\n",
      "INFO - 2019-02-20 16:48:08,975 - instantiating class <class 'PatientVec.models.modules.SelfAttention.SelfAttention'> from params {'similarity': {'type': 'additive', 'hidden_size': 128, 'tensor_1_dim': 256}} and extras {}\n",
      "INFO - 2019-02-20 16:48:08,976 - instantiating class <class 'PatientVec.models.modules.UniSimilarity.UniSimilarity'> from params {'type': 'additive', 'hidden_size': 128, 'tensor_1_dim': 256} and extras {}\n",
      "INFO - 2019-02-20 16:48:08,977 - attention.similarity.type = additive\n",
      "INFO - 2019-02-20 16:48:08,978 - instantiating class <class 'PatientVec.models.modules.UniSimilarity.UniAdditiveSimilarity'> from params {'hidden_size': 128, 'tensor_1_dim': 256} and extras {}\n",
      "INFO - 2019-02-20 16:48:08,978 - attention.similarity.tensor_1_dim = 256\n",
      "INFO - 2019-02-20 16:48:08,979 - attention.similarity.hidden_size = 128\n",
      "INFO - 2019-02-20 16:48:08,981 - attention.normaliser = softmax\n",
      "INFO - 2019-02-20 16:48:08,982 - decoder.input_dim = 398\n",
      "INFO - 2019-02-20 16:48:08,982 - decoder.num_layers = 2\n",
      "INFO - 2019-02-20 16:48:08,983 - decoder.hidden_dims = [128, 1]\n",
      "INFO - 2019-02-20 16:48:08,984 - decoder.activations = ['tanh', 'linear']\n",
      "INFO - 2019-02-20 16:48:08,984 - decoder.dropout = 0.0\n",
      "INFO - 2019-02-20 16:48:08,986 - instantiating class <class 'PatientVec.models.modules.Predictor.Predictor'> from params {'type': 'binary'} and extras {}\n",
      "INFO - 2019-02-20 16:48:08,987 - predictor.type = binary\n",
      "INFO - 2019-02-20 16:48:08,987 - instantiating class <class 'PatientVec.models.modules.Predictor.Binary_Predictor'> from params {} and extras {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Embedding\n",
      "Pos Percentage [0.20937082]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-20 16:48:11,845 - Maximum Sentence Length 588265.000000 , 90 percentile length 19174.500000 ... \n",
      "INFO - 2019-02-20 16:48:11,850 - Pos Percentage of remaining data ... \n",
      "INFO - 2019-02-20 16:48:11,856 - [0.19723338]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143d9597c22341888eabe8783141f2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=211), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'accuracy': 0.8188308790718429, 'roc_auc': 0.7608705858877524, 'pr_auc': 0.4742785860170263}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>micro avg</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>5397.000</td>\n",
       "      <td>1326.000</td>\n",
       "      <td>6723.000</td>\n",
       "      <td>6723.000</td>\n",
       "      <td>6723.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1  micro avg  macro avg  weighted avg\n",
       "f1-score      0.896     0.315      0.819      0.605         0.781\n",
       "precision     0.833     0.619      0.819      0.726         0.791\n",
       "recall        0.968     0.211      0.819      0.590         0.819\n",
       "support    5397.000  1326.000   6723.000   6723.000      6723.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_attention_config = attention_configs[2](data, structured=True, args=args)\n",
    "lstm_attn_eval = Evaluator(BasicCT, get_latest_model(os.path.join('outputs', lstm_attention_config['exp_config']['exp_name'])))\n",
    "dev_data = data.get_data('dev', structured=True)\n",
    "dev_data = data.filter_data_length(dev_data, truncate=90)\n",
    "lstm_outputs = lstm_attn_eval.evaluate(dev_data, save_results=False)\n",
    "del lstm_attn_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Percentage [0.20937082]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-20 16:50:00,000 - Maximum Sentence Length 588265.000000 , 90 percentile length 19174.500000 ... \n",
      "INFO - 2019-02-20 16:50:00,005 - Pos Percentage of remaining data ... \n",
      "INFO - 2019-02-20 16:50:00,011 - [0.19723338]\n"
     ]
    }
   ],
   "source": [
    "dev_data = data.get_data('dev', structured=True)\n",
    "dev_data = data.filter_data_length(dev_data, truncate=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention_comparison import get_common_attended_words\n",
    "X_1 = [dev_data.X[i] for i in range(len(dev_data.y)) if dev_data.y[i] == 1]\n",
    "attn_1 = [lstm_outputs['attentions'][i] for i in range(len(dev_data.y)) if dev_data.y[i] == 1]\n",
    "common_words = get_common_attended_words(X_1, attn_1, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, freqs = list(zip(*common_words.most_common(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = data.vocab.map_to_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 411),\n",
       " ('.', 318),\n",
       " ('with', 305),\n",
       " ('of', 243),\n",
       " ('and', 212),\n",
       " ('disease', 161),\n",
       " ('to', 146),\n",
       " ('p', 124),\n",
       " ('family', 120),\n",
       " ('contraindications', 100),\n",
       " ('diagnosis', 100),\n",
       " ('meeting', 93),\n",
       " ('placement', 93),\n",
       " ('for', 89),\n",
       " ('ascites', 87),\n",
       " ('from', 80),\n",
       " ('/', 80),\n",
       " ('pleural', 80),\n",
       " ('skin', 77),\n",
       " ('line', 75),\n",
       " ('team', 72),\n",
       " ('dnr', 69),\n",
       " ('coccyx', 68),\n",
       " ('metastatic', 62),\n",
       " (':', 61),\n",
       " ('duoderm', 59),\n",
       " ('edema', 57),\n",
       " ('multiple', 56),\n",
       " ('care', 55),\n",
       " ('is', 55),\n",
       " ('cancer', 52),\n",
       " ('poor', 49),\n",
       " ('fluid', 49),\n",
       " ('aortic', 49),\n",
       " ('stage', 47),\n",
       " ('post', 45),\n",
       " ('liver', 44),\n",
       " (';', 43),\n",
       " ('picc', 42),\n",
       " ('subdural', 42),\n",
       " ('-', 42),\n",
       " ('reason_for_this_examination', 41),\n",
       " ('made', 41),\n",
       " ('a', 41),\n",
       " ('herniation', 41),\n",
       " ('status', 41),\n",
       " ('awaiting', 40),\n",
       " ('draining', 39),\n",
       " ('prognosis', 39),\n",
       " ('extremity', 39)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(words, freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ascites',\n",
       "  'awaiting',\n",
       "  'cancer',\n",
       "  'coccyx',\n",
       "  'dnr',\n",
       "  'duoderm',\n",
       "  'meeting',\n",
       "  'metastatic',\n",
       "  'picc',\n",
       "  'prognosis',\n",
       "  'subdural'},\n",
       " {',',\n",
       "  '-',\n",
       "  '.',\n",
       "  '/',\n",
       "  ':',\n",
       "  ';',\n",
       "  'a',\n",
       "  'and',\n",
       "  'aortic',\n",
       "  'care',\n",
       "  'contraindications',\n",
       "  'diagnosis',\n",
       "  'disease',\n",
       "  'draining',\n",
       "  'edema',\n",
       "  'extremity',\n",
       "  'family',\n",
       "  'fluid',\n",
       "  'for',\n",
       "  'from',\n",
       "  'herniation',\n",
       "  'is',\n",
       "  'line',\n",
       "  'liver',\n",
       "  'made',\n",
       "  'multiple',\n",
       "  'of',\n",
       "  'p',\n",
       "  'placement',\n",
       "  'pleural',\n",
       "  'poor',\n",
       "  'post',\n",
       "  'reason_for_this_examination',\n",
       "  'skin',\n",
       "  'stage',\n",
       "  'status',\n",
       "  'team',\n",
       "  'to',\n",
       "  'with'},\n",
       " {'7.31',\n",
       "  'admissions',\n",
       "  'amiodarone',\n",
       "  'anasarca',\n",
       "  'ankylosing',\n",
       "  'bmt',\n",
       "  'brown',\n",
       "  'chronically',\n",
       "  'cmo',\n",
       "  'coagulopathy',\n",
       "  'coarse',\n",
       "  'dark',\n",
       "  'dialysis',\n",
       "  'endovascular',\n",
       "  'enteric',\n",
       "  'hospice',\n",
       "  'icteric',\n",
       "  'iv_contrast',\n",
       "  'j',\n",
       "  'jaundiced',\n",
       "  'listerine',\n",
       "  'metastases',\n",
       "  'monday',\n",
       "  'narrowing',\n",
       "  'onc',\n",
       "  'palliative',\n",
       "  'paracentesis',\n",
       "  'pea',\n",
       "  'prednisone',\n",
       "  'rf',\n",
       "  'tears',\n",
       "  'thoracentesis',\n",
       "  'times',\n",
       "  'transplant',\n",
       "  'transtentorial',\n",
       "  'tube',\n",
       "  'tumor',\n",
       "  'vd',\n",
       "  'vre'})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(words) & set(words_tf), set(words) - set(words_tf), set(words_tf) - set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baselines\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name})\n",
    "lda.train(train_data)\n",
    "lda.evaluate(dev_data, save_results=True)\n",
    "print(lda.get_topics(n=10))\n",
    "topics = lda.get_topics(n=10)\n",
    "print([topics[i] for i in np.argsort(lda.lda_classifier.coef_[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[topics[i] for i in np.argsort(lda.lda_classifier.coef_[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = outputs['predictions'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import collapse_and_print_word_attn, print_sent_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "collapse_and_print_word_attn(data.vocab, dev_data.X[n], outputs['word_attentions'][n])\n",
    "print_sent_attn(data.vocab, dev_data.X[n], outputs['sentence_attentions'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['sentence_attentions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = [kendalltau(range(len(outputs['sentence_attentions'][i])), outputs['sentence_attentions'][i]) \n",
    "         for i in range(len(outputs['sentence_attentions']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, leng = zip(*[(x[0], y) for x, y in zip(corrs, [len(z) for z in outputs['sentence_attentions']]) if x[0] == x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rho, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval, leng1 = zip(*[(x[1], y) for x, y in zip(corrs, [len(z) for z in outputs['sentence_attentions']]) if x[1] == x[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Models\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import generate_latex_tables\n",
    "keys_to_use = ['1/precision', '1/recall', '1/f1-score', 'accuracy', 'roc_auc', 'pr_auc']\n",
    "generate_latex_tables(data, keys_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
