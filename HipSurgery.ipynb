{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for surgery in ['hip', 'knee'] :\n",
    "    for yr in ['1', '2', '3', '0.5', '0.25'] :\n",
    "        dataset = surgery + '_' + yr + 'yr'\n",
    "        %run \"Discovery Experiments\"/run_models.py --dataset {dataset} --data_dir=. --output_dir='outputs/' \\\n",
    "        --exp_types lr lda vanilla attention --structured --display --bsize 8 --n_iters=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for surgery in ['hip', 'knee'] :\n",
    "    for yr in ['1', '2', '3', '0.5', '0.25'] :\n",
    "        dataset = surgery + '_' + yr\n",
    "        %run \"Discovery Experiments\"/run_models.py --dataset {dataset} --data_dir=. --output_dir='outputs/' \\\n",
    "        --exp_types vanilla attention --display --bsize 8 --n_iters=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-04-13 15:20:39,856 - Reading Structured data ...\n",
      "INFO - 2019-04-13 15:20:40,635 - Reading Notes ...\n",
      "INFO - 2019-04-13 15:20:42,867 - Stratifying ...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Run experiments on a dataset')\n",
    "parser.add_argument(\"--data_dir\", type=str, required=True)\n",
    "\n",
    "args, extras = parser.parse_known_args(['--data_dir=.'])\n",
    "args.extras = extras\n",
    "\n",
    "dataset = dataloaders['both_1yr'](args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Percentage [0.04390465 0.44930597 0.05099578 0.55069403]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-04-13 15:21:56,564 - Maximum Sentence Length 585530.000000 , 90 percentile length 19689.000000 ... \n",
      "INFO - 2019-04-13 15:21:58,877 - Truncated all ...\n",
      "INFO - 2019-04-13 15:21:58,884 - Idxs removed []...\n",
      "INFO - 2019-04-13 15:21:59,206 - Maximum Sentence Length 119600.000000 , 90 percentile length 20149.000000 ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Percentage [0.04519774 0.4519774  0.06638418 0.5480226 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-04-13 15:21:59,569 - Truncated all ...\n",
      "INFO - 2019-04-13 15:21:59,571 - Idxs removed []...\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset.filter_data_length(dataset.get_data('train', structured=False), 90)\n",
    "dev_data = dataset.filter_data_length(dataset.get_data('dev', structured=False), 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Experiments.modifiable_config_exp import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LSTM(dataset, False, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-04-13 15:21:18,887 - instantiating class <class 'models.Model.Model'> from params {'type': 'seq_classifier', 'embedder': {'type': 'token_embedder', 'vocab_size': 26447, 'embed_size': 200, 'embedding_file': './preprocess/MultiTaskSurgery/1_yrs/embedding_matrix.npy'}, 'decoder': {'num_layers': 1, 'hidden_dims': [128], 'activations': ['tanh']}, 'predictor': {'type': 'multitask', 'n_tasks': 2, 'task_decoder': {'num_layers': 1, 'hidden_dims': [1], 'activations': ['linear'], 'input_dim': 128}}, 'structured': {'use_structured': False}, 'encoder': {'type': 'lstm', 'hidden_size': 128}} and extras {}\n",
      "INFO - 2019-04-13 15:21:18,888 - type = seq_classifier\n",
      "INFO - 2019-04-13 15:21:18,889 - instantiating class <class 'models.modules.Embedder.Embedder'> from params {'type': 'token_embedder', 'vocab_size': 26447, 'embed_size': 200, 'embedding_file': './preprocess/MultiTaskSurgery/1_yrs/embedding_matrix.npy'} and extras {}\n",
      "INFO - 2019-04-13 15:21:18,889 - embedder.type = token_embedder\n",
      "INFO - 2019-04-13 15:21:18,890 - instantiating class <class 'models.modules.Embedder.TokenEmbedder'> from params {'vocab_size': 26447, 'embed_size': 200, 'embedding_file': './preprocess/MultiTaskSurgery/1_yrs/embedding_matrix.npy'} and extras {}\n",
      "INFO - 2019-04-13 15:21:18,891 - embedder.vocab_size = 26447\n",
      "INFO - 2019-04-13 15:21:18,892 - embedder.embed_size = 200\n",
      "INFO - 2019-04-13 15:21:18,892 - embedder.embedding_file = ./preprocess/MultiTaskSurgery/1_yrs/embedding_matrix.npy\n",
      "INFO - 2019-04-13 15:21:18,924 - instantiating class <class 'models.modules.Encoder.Encoder'> from params {'type': 'lstm', 'hidden_size': 128} and extras {'input_size': 200}\n",
      "INFO - 2019-04-13 15:21:18,925 - encoder.type = lstm\n",
      "INFO - 2019-04-13 15:21:18,926 - instantiating class <class 'models.modules.Encoder.wrap_pytorch_rnn.<locals>.BiRNNEncoder'> from params {'hidden_size': 128} and extras {'input_size': 200}\n",
      "INFO - 2019-04-13 15:21:18,926 - encoder.hidden_size = 128\n",
      "INFO - 2019-04-13 15:21:18,930 - decoder.input_dim = 256\n",
      "INFO - 2019-04-13 15:21:18,930 - decoder.num_layers = 1\n",
      "INFO - 2019-04-13 15:21:18,931 - decoder.hidden_dims = [128]\n",
      "INFO - 2019-04-13 15:21:18,931 - decoder.activations = ['tanh']\n",
      "INFO - 2019-04-13 15:21:18,932 - decoder.dropout = 0.0\n",
      "INFO - 2019-04-13 15:21:18,934 - instantiating class <class 'models.modules.Predictor.Predictor'> from params {'type': 'multitask', 'n_tasks': 2, 'task_decoder': {'num_layers': 1, 'hidden_dims': [1], 'activations': ['linear'], 'input_dim': 128}} and extras {}\n",
      "INFO - 2019-04-13 15:21:18,935 - predictor.type = multitask\n",
      "INFO - 2019-04-13 15:21:18,935 - instantiating class <class 'models.modules.Predictor.MultiTask_predictor'> from params {'n_tasks': 2, 'task_decoder': {'num_layers': 1, 'hidden_dims': [1], 'activations': ['linear'], 'input_dim': 128}} and extras {}\n",
      "INFO - 2019-04-13 15:21:18,936 - predictor.n_tasks = 2\n",
      "INFO - 2019-04-13 15:21:18,936 - predictor.task_decoder.input_dim = 128\n",
      "INFO - 2019-04-13 15:21:18,937 - predictor.task_decoder.num_layers = 1\n",
      "INFO - 2019-04-13 15:21:18,937 - predictor.task_decoder.hidden_dims = [1]\n",
      "INFO - 2019-04-13 15:21:18,938 - predictor.task_decoder.activations = ['linear']\n",
      "INFO - 2019-04-13 15:21:18,938 - predictor.task_decoder.dropout = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Embedding\n"
     ]
    }
   ],
   "source": [
    "from models.Vanilla import ClassificationTrainer\n",
    "trainer = ClassificationTrainer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1a55633df253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/ramin/Share-drive/SurgeryData/PatientVec/models/Vanilla.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ramin/Share-drive/SurgeryData/PatientVec/models/Trainer.py\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mclass_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_class_weight_for_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ramin/Share-drive/SurgeryData/PatientVec/models/Trainer.py\u001b[0m in \u001b[0;36mcompute_class_weight_for_y\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_class_weight_for_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[0;34m(class_weight, classes, y)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         raise ValueError(\"classes should include all valid labels that can \"\n\u001b[1;32m     43\u001b[0m                          \"be in y\")\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "trainer.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
