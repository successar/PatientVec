{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Run Diagnosis experiments')\n",
    "parser.add_argument(\"--data_dir\", type=str, required=True)\n",
    "parser.add_argument('--display', dest='display', action='store_true')\n",
    "parser.add_argument(\"--output_dir\", type=str)\n",
    "parser.add_argument(\"--mock\", dest='mock', action='store_true')\n",
    "\n",
    "args = parser.parse_args(['--data_dir=.', '--output_dir=outputs/', '--display'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-20 19:23:57,918 - Reading Structured data ...\n",
      "INFO - 2019-02-20 19:23:58,132 - Reading Notes ...\n",
      "INFO - 2019-02-20 19:23:59,402 - Stratifying ...\n"
     ]
    }
   ],
   "source": [
    "from dataloaders import hip_dataset, knee_dataset\n",
    "data = hip_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Percentage [0.10457297]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2019-02-20 19:24:00,125 - Maximum Sentence Length 610378.000000 , 100 percentile length 610378.000000 ... \n",
      "INFO - 2019-02-20 19:24:00,126 - Pos Percentage of remaining data ... \n",
      "INFO - 2019-02-20 19:24:00,127 - [0.10457297]\n",
      "INFO - 2019-02-20 19:24:00,419 - Maximum Sentence Length 119250.000000 , 100 percentile length 119250.000000 ... \n",
      "INFO - 2019-02-20 19:24:00,419 - Pos Percentage of remaining data ... \n",
      "INFO - 2019-02-20 19:24:00,420 - [0.0875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Percentage [0.0875]\n"
     ]
    }
   ],
   "source": [
    "train_data = data.filter_data_length(data.get_data('train', structured=False), truncate=100)\n",
    "dev_data = data.filter_data_length(data.get_data('dev', structured=False), truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d94a4413b64b5c96b1bdf1d9719e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2974), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabb19e89eac41e0ba348b88098deab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2974), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d659517d561143a6829103c8e1191a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2974), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fit BOW Classifier ...\n",
      "Fit TFIDF Classifier ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d6c3eecfce4ea496e7c9f7e4255d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=640), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0dac28b798948acab5d25b7926f664f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=640), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BOW\n",
      "{'accuracy': 0.8328125, 'roc_auc': 0.8195327788649707, 'pr_auc': 0.3475973485547539}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>micro avg</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>584.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>640.000</td>\n",
       "      <td>640.000</td>\n",
       "      <td>640.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0.0     1.0  micro avg  macro avg  weighted avg\n",
       "f1-score     0.903   0.409      0.833      0.656         0.859\n",
       "precision    0.963   0.296      0.833      0.630         0.905\n",
       "recall       0.849   0.661      0.833      0.755         0.833\n",
       "support    584.000  56.000    640.000    640.000       640.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF\n",
      "{'accuracy': 0.840625, 'roc_auc': 0.823752446183953, 'pr_auc': 0.37385566836057593}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>micro avg</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>584.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>640.000</td>\n",
       "      <td>640.000</td>\n",
       "      <td>640.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0.0     1.0  micro avg  macro avg  weighted avg\n",
       "f1-score     0.909   0.378      0.841      0.643         0.862\n",
       "precision    0.953   0.287      0.841      0.620         0.895\n",
       "recall       0.868   0.554      0.841      0.711         0.841\n",
       "support    584.000  56.000    640.000    640.000       640.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PatientVec.models.baselines.LR import LR, LDA\n",
    "\n",
    "lr = LR({'vocab' : data.vocab, 'stop_words' : True, 'exp_name' : data.name, 'type' : 'classifier', 'norm' : 'l2'})\n",
    "lr.train(train_data)\n",
    "lr.evaluate(dev_data, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loos onto attempt today partial infiltr stool thr intraop took surround smooth cortex great exposur extub pneumonia came diamet loosen fx swell heterotop communic lie fi prosthes erythromycin gram amount new tetracyclin underneath stat prosthet infect debrid suscept picc revis\n",
      "----------\n",
      "vertic septal synovial aforement great fen workup intraventricular haloperidol mom arthrogram cortex fibrous erythromycin fx tetracyclin cardiomegali disengag extub allograft lot came heterotop clamp gram platlet debrid communic subjac suscept prosthes lie underneath explant wndclt infect prosthet stat picc revis\n",
      "----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiOutputClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5bd47508b31d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SurgeryData/PatientVec/models/baselines/LR.py\u001b[0m in \u001b[0;36mprint_all_features\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_idf_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbow_with_structured_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_idf_with_structured_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SurgeryData/PatientVec/models/baselines/LR.py\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(self, classifier, estimator, n)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         return [self.bowder.vocab.idx2word[self.bowder.map_bow_to_vocab[x]] for x in \n\u001b[0;32m---> 85\u001b[0;31m                     np.argsort(classifier.estimators_[estimator].coef_[0][:len(self.bowder.words_to_keep)])[-n:]]\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiOutputClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "lr.print_all_features(n=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Experiments\n",
    "======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatientVec.models.Vanilla import ClassificationTrainer as BasicCT\n",
    "from PatientVec.models.Hierarchical import ClassificationTrainer as HierCT\n",
    "from PatientVec.trainer import Trainer, Evaluator\n",
    "from PatientVec.Experiments.modifiable_config_exp import vanilla_configs, attention_configs, hierarchical_configs, structured_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatientVec.Experiments.hyperparam_exps import get_basic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data = get_basic_data(data, structured=False, truncate=98)\n",
    "\n",
    "for e in attention_configs :\n",
    "    config = e(data, structured=False, args=args)\n",
    "    if args.output_dir is not None :\n",
    "        config['exp_config']['basepath'] = args.output_dir\n",
    "    config['training_config']['common']['bsize'] = 8\n",
    "    config['training_config']['type'] = 'RMSprop'\n",
    "    print(config)\n",
    "\n",
    "    trainer = Trainer(BasicCT, config, _type=data.metrics_type, display_metrics=True)\n",
    "    trainer.train(train_data, dev_data, n_iters=15, save_on_metric=data.save_on_metric)\n",
    "\n",
    "    evaluator = Evaluator(BasicCT, trainer.model.dirname, _type=data.metrics_type, display_metrics=True)\n",
    "    _ = evaluator.evaluate(dev_data, save_results=True)\n",
    "    print('='*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data = get_basic_data(data, structured=False, truncate=98)\n",
    "\n",
    "for e in vanilla_configs :\n",
    "    config = e(data, structured=False, args=args)\n",
    "    if args.output_dir is not None :\n",
    "        config['exp_config']['basepath'] = args.output_dir\n",
    "    config['training_config']['common']['bsize'] = 8\n",
    "    print(config)\n",
    "\n",
    "    trainer = Trainer(BasicCT, config, _type=data.metrics_type, display_metrics=True)\n",
    "    trainer.train(train_data, dev_data, n_iters=15, save_on_metric=data.save_on_metric)\n",
    "\n",
    "    evaluator = Evaluator(BasicCT, trainer.model.dirname, _type=data.metrics_type, display_metrics=True)\n",
    "    _ = evaluator.evaluate(dev_data, save_results=True)\n",
    "    print('='*300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Models\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import generate_latex_tables\n",
    "keys_to_use = ['1/precision', '1/recall', '1/f1-score', 'accuracy', 'roc_auc', 'pr_auc']\n",
    "generate_latex_tables(data, keys_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
